{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrYHSDCbhgQJ",
        "outputId": "c6094285-2aa6-4d86-fad7-e6dfac8a1b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visitando http://home.cern/\n",
            "Visitando http://home.cern/#main-content\n",
            "Visitando http://home.cern/about\n",
            "Visitando http://home.cern/about#main-content\n",
            "Visitando http://home.cern/about/who-we-are\n",
            "Visitando http://home.cern/about/who-we-are#main-content\n",
            "Visitando http://home.cern/about/who-we-are/our-mission\n",
            "Visitando http://home.cern/about/who-we-are/our-mission#main-content\n",
            "Visitando http://home.cern/about/who-we-are/our-governance\n",
            "Visitando http://home.cern/about/who-we-are/our-governance#main-content\n",
            "Visitando http://home.cern/about/who-we-are/our-governance/member-states\n",
            "Visitando http://home.cern/about/who-we-are/our-governance/member-states#main-content\n",
            "Visitando http://home.cern/about/who-we-are/our-history\n",
            "Visitando http://home.cern/about/who-we-are/our-history#main-content\n",
            "Visitando http://home.cern/about/who-we-are/our-people\n",
            "Visitando http://home.cern/about/who-we-are/our-people#main-content\n",
            "Visitando http://home.cern/about/what-we-do\n",
            "Visitando http://home.cern/about/what-we-do#main-content\n",
            "Visitando http://home.cern/about/what-we-do/fundamental-research\n"
          ]
        }
      ],
      "source": [
        "from urllib.parse import urljoin\n",
        "from html.parser import HTMLParser\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "class Collector(HTMLParser):\n",
        "    'coleta URLs de hyperklink em uma lista'\n",
        "    def __init__(self, url):\n",
        "        'inicializa analisador, o URL e uma lista'\n",
        "        HTMLParser.__init__(self)\n",
        "        self.url = url\n",
        "        self.links = []\n",
        "\n",
        "    def handle_starttag(self, tag, attrs):\n",
        "        'coleta URLs de hyperlink em sua forma absoluta'\n",
        "        if tag == 'a':\n",
        "            for attr in attrs:\n",
        "                if attr[0] == 'href':\n",
        "                    # constrÃ³i URL absoluto\n",
        "                    absolute = urljoin(self.url, attr[1])\n",
        "                    if absolute[:4] == 'http': # coleta URLs HTTP\n",
        "                        self.links.append(absolute)\n",
        "\n",
        "    def getLinks(self):\n",
        "        'retorna URLs de hyperlink em seu formato absoluto'\n",
        "        return self.links\n",
        "\n",
        "def analyze(url):\n",
        "    '''retorna a lista de links http, em formato absoluto,\n",
        "        na pÃ¡gina Web com URL url'''\n",
        "    print('Visitando', url) # para teste\n",
        "    # obtÃ©m links na pÃ¡gina Web\n",
        "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    content = urlopen(req).read().decode()\n",
        "    collector = Collector(url)\n",
        "    collector.feed(content)\n",
        "    urls = collector.getLinks()       # urls Ã© a lista de links\n",
        "    # anÃ¡lise do conteÃºdo da pÃ¡gina Web ainda a ser feita\n",
        "    return urls\n",
        "visited = set()\n",
        "def crawl(url):\n",
        "    'crawler Web recursiva que chama analyze() em cada pÃ¡gina Web'\n",
        "    # inclui url para conjunto de pÃ¡ginas visitadas\n",
        "    global visited       # embora nÃ£o necessÃ¡rio, avisa ao programador\n",
        "    visited.add(url)\n",
        "    if (len(visited)>=maxlinks):\n",
        "        return\n",
        "    # analyze() retorna uma lista de URLs de hyperlink no URL da pÃ¡gina Web\n",
        "    links = analyze(url)\n",
        "    # continua recursivamente a verificaÃ§Ã£o de cada link em links\n",
        "    for link in links:\n",
        "        if (externalLink):\n",
        "            follow = externalLink\n",
        "        else: follow = str(link).find(uri)>=0\n",
        "        if (link not in visited) and follow:\n",
        "            try: # bloco try porque o link pode nÃ£o ser um arquivo HTML vÃ¡lido\n",
        "                crawl(link)\n",
        "            except:            # se uma exceÃ§Ã£o for lanÃ§ada\n",
        "                pass           # ignora e prossegue.\n",
        "\n",
        "maxlinks= 20 # Limita o crawler para uma quantidade maxima\n",
        "externalLink=False # Flag para permitir seguir links fora do site\n",
        "uri='http://youtube.com/'\n",
        "crawl(uri)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
